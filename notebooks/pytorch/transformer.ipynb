{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"transformer.ipynb のコピー","provenance":[{"file_id":"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/text/transformer.ipynb","timestamp":1604743168056}],"collapsed_sections":["s_qNSzzyaCbD"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s_qNSzzyaCbD"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","id":"jmjh290raIky","executionInfo":{"status":"ok","timestamp":1604736914559,"user_tz":-540,"elapsed":1694,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0Qjg6vuaHNt"},"source":["# 言語理解のためのTransformerモデル"]},{"cell_type":"markdown","metadata":{"id":"AOpGoE2T-YXS"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n","    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n","    View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/tutorials/text/transformer.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n","    Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/text/transformer.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n","    View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"tudzcncJXetB"},"source":["Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"]},{"cell_type":"markdown","metadata":{"id":"M-f8TnGpE_ex"},"source":["このチュートリアルでは、ポルトガル語を英語に翻訳する<a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformerモデル</a>を訓練します。これは上級編のサンプルで、[テキスト生成](text_generation.ipynb)や[アテンション（注意機構）](nmt_with_attention.ipynb)の知識を前提としています。\n","\n","Transformerモデルの背後にある中心的なアイデアは*セルフアテンション（自己注意）*、 つまり、シーケンスの表現を計算するために入力シーケンスの異なる位置に注意を払うことができることにあります。\n","\n","Transformerモデルは、[RNNs](text_classification_rnn.ipynb)や[CNNs](../images/intro_to_cnns.ipynb)の代わりに セルフアテンション・レイヤーを重ねたものを使って、可変長の入力を扱います。この一般的なアーキテクチャにはいくつもの利点があります。\n","\n","* データの中の時間的／空間的な関係を前提にしません。これは、オブジェクトの集合（例えば、[StarCraftのユニット](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8))を扱うには理想的です。\n","* レイヤーの出力はRNNのような系列ではなく、並列に計算可能です。\n","* たくさんのRNNのステップや畳み込み層を経ることなく、離れた要素どうしが互いの出力に影響を与えることができます（例えば、[Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf)を参照)。\n","* 長距離の依存関係を学習可能です。これは、シーケンスを扱うタスクにおいては難しいことです。\n","\n","このアーキテクチャの欠点は次のようなものです。\n","\n","* 時系列では、あるタイムステップの出力が、入力とその時の隠れ状態だけからではなく、*過去全て*から計算されます。\n","* テキストのように、入力に時間的／空間的な関係が*存在する*場合、何らかの位置エンコーディングを追加しなければなりません。さもなければ、モデルは実質的にバッグ・オブ・ワード（訳注：Bag of Word、含まれる単語の集合）を見ることになります。\n","\n","このノートブックのモデルを訓練したあとには、ポルトガル語の文を入力し、英語の翻訳を得ることができます。\n","\n","<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"]},{"cell_type":"code","metadata":{"id":"JjJJyJTZYebt","executionInfo":{"status":"ok","timestamp":1604737064633,"user_tz":-540,"elapsed":4879,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"210bcf7b-d9fa-4e00-8707-53c6e37e833a","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install tf-nightly\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.5.0.dev20201106)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.19.4)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.32.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.4.3)\n","Requirement already satisfied: tb-nightly~=2.4.0.a in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.4.0a20201106)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.35.1)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n","Requirement already satisfied: protobuf~=3.13.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.13.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.10.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n","Requirement already satisfied: tf-estimator-nightly~=2.4.0.dev in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.4.0.dev2020102301)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (0.4.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (50.3.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.4.0.a->tf-nightly) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly) (4.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly~=2.4.0.a->tf-nightly) (2.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.4.0.a->tf-nightly) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.4.0.a->tf-nightly) (3.4.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fd1NWMxjfsDd"},"source":["## 入力パイプラインの設定"]},{"cell_type":"markdown","metadata":{"id":"t4_Qt8W1hJE_"},"source":["[TFDS](https://www.tensorflow.org/datasets)を使って、[TED Talks Open Translation Project](https://www.ted.com/participate/translate)から[Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt)をロードします。\n","\n","このデータセットには、約50000の訓練用サンプルと、1100の検証用サンプル、2000のテスト用サンプルが含まれています。"]},{"cell_type":"code","metadata":{"id":"8q9t4FmN96eN","executionInfo":{"status":"ok","timestamp":1604737066184,"user_tz":-540,"elapsed":541,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n","                               as_supervised=True)\n","train_examples, val_examples = examples['train'], examples['validation']"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCEKotqosGfq"},"source":["訓練用データセットから、カスタムのサブワード・トークナイザーを作成します。"]},{"cell_type":"code","metadata":{"id":"KVBg5Q8tBk5z","executionInfo":{"status":"ok","timestamp":1604737476929,"user_tz":-540,"elapsed":132876,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n","\n","tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DYWukNFkGQN","executionInfo":{"status":"ok","timestamp":1604737476932,"user_tz":-540,"elapsed":124485,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"7dc71ba2-2709-40f4-f260-7ee03efaf1a7","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_string = 'Transformer is awesome.'\n","\n","tokenized_string = tokenizer_en.encode(sample_string)\n","print ('Tokenized string is {}'.format(tokenized_string))\n","\n","original_string = tokenizer_en.decode(tokenized_string)\n","print ('The original string: {}'.format(original_string))\n","\n","assert original_string == sample_string"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n","The original string: Transformer is awesome.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o9KJWJjrsZ4Y"},"source":["このトークナイザーは、単語が辞書にない場合には文字列をサブワードに分解してエンコードします。"]},{"cell_type":"code","metadata":{"id":"bf2ntBxjkqK6","executionInfo":{"status":"ok","timestamp":1604737476932,"user_tz":-540,"elapsed":124475,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"4817b406-9fe7-4a66-ac95-fb673e56219f","colab":{"base_uri":"https://localhost:8080/"}},"source":["for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["7915 ----> T\n","1248 ----> ran\n","7946 ----> s\n","7194 ----> former \n","13 ----> is \n","2799 ----> awesome\n","7877 ----> .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bcRp7VcQ5m6g","executionInfo":{"status":"ok","timestamp":1604737476932,"user_tz":-540,"elapsed":124471,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["BUFFER_SIZE = 20000\n","BATCH_SIZE = 64"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGi4PoVakxdc"},"source":["入力とターゲットに開始及び終了トークンを追加します。"]},{"cell_type":"code","metadata":{"id":"UZwnPr4R055s","executionInfo":{"status":"ok","timestamp":1604737476933,"user_tz":-540,"elapsed":124469,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def encode(lang1, lang2):\n","  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n","      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n","\n","  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n","      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n","  \n","  return lang1, lang2"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tx1sFbR-9fRs"},"source":["データセットの各要素にこの関数を適用するために、`Dataset.map`を使いたいと思います。`Dataset.map`はグラフモードで動作します。\n","\n","* グラフテンソルは値を持ちません。\n","* グラフモードでは、TensorFlowの演算と関数しか使えません。\n","\n","このため、この関数を直接`.map`することはできません。`tf.py_function`でラップする必要があります。`tf.py_function`は（値とそれにアクセスするための`.numpy()`メソッドを持つ）通常のテンソルを、ラップされたPython関数に渡します。"]},{"cell_type":"code","metadata":{"id":"Mah1cS-P70Iz","executionInfo":{"status":"ok","timestamp":1604737476933,"user_tz":-540,"elapsed":124466,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def tf_encode(pt, en):\n","  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n","  result_pt.set_shape([None])\n","  result_en.set_shape([None])\n","\n","  return result_pt, result_en"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6JrGp5Gek6Ql"},"source":["Note: このサンプルを小さく、より速くするため、長さが40トークンを超えるサンプルを削除します。"]},{"cell_type":"code","metadata":{"id":"2QEgbjntk6Yf","executionInfo":{"status":"ok","timestamp":1604737476933,"user_tz":-540,"elapsed":124462,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["MAX_LENGTH = 40"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"c081xPGv1CPI","executionInfo":{"status":"ok","timestamp":1604737476934,"user_tz":-540,"elapsed":124460,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def filter_max_length(x, y, max_length=MAX_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fw2YSL3SXE1","executionInfo":{"status":"ok","timestamp":1604737476934,"user_tz":-540,"elapsed":124458,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["train_preprocessed = (\n","    train_examples\n","    .map(tf_encode) \n","    .filter(filter_max_length)\n","    # 読み取り時のスピードアップのため、データセットをメモリ上にキャッシュする\n","    .cache()\n","    .shuffle(BUFFER_SIZE))\n","\n","val_preprocessed = (\n","    val_examples\n","    .map(tf_encode)\n","    .filter(filter_max_length))        "],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q9CP7sLlFMpb"},"source":["パディングとバッチ化の両方を行います。"]},{"cell_type":"code","metadata":{"id":"9mk9AZdZ5bcS","executionInfo":{"status":"ok","timestamp":1604737476935,"user_tz":-540,"elapsed":124455,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["train_dataset = (train_preprocessed\n","                 .padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\n","                 .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","\n","val_dataset = (val_preprocessed\n","               .padded_batch(BATCH_SIZE,  padded_shapes=([None], [None])))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIbblR_Ri-FI"},"source":["Note: **TensorFlow 2.2** から、padded_shapes は必須ではなくなりました。デフォルトではすべての軸をバッチ中で最も長いものに合わせてパディングします。"]},{"cell_type":"code","metadata":{"id":"u5rsX9zLlK8t","executionInfo":{"status":"ok","timestamp":1604737476935,"user_tz":-540,"elapsed":124451,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["train_dataset = (train_preprocessed\n","                 .padded_batch(BATCH_SIZE)\n","                 .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","\n","val_dataset = (val_preprocessed\n","               .padded_batch(BATCH_SIZE))"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AizWyxQ64wB0"},"source":["後でコードをテストするために、検証用データセットからバッチを一つ取得しておきます。"]},{"cell_type":"code","metadata":{"id":"_fXvfYVfQr2n","executionInfo":{"status":"ok","timestamp":1604737477165,"user_tz":-540,"elapsed":124678,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"7c54293c-1889-4301-c977-e0976026d057","colab":{"base_uri":"https://localhost:8080/"}},"source":["pt_batch, en_batch = next(iter(val_dataset))\n","pt_batch, en_batch"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n"," array([[8214,  342, 3032, ...,    0,    0,    0],\n","        [8214,   95,  198, ...,    0,    0,    0],\n","        [8214, 4479, 7990, ...,    0,    0,    0],\n","        ...,\n","        [8214,  584,   12, ...,    0,    0,    0],\n","        [8214,   59, 1548, ...,    0,    0,    0],\n","        [8214,  118,   34, ...,    0,    0,    0]])>,\n"," <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n"," array([[8087,   98,   25, ...,    0,    0,    0],\n","        [8087,   12,   20, ...,    0,    0,    0],\n","        [8087,   12, 5453, ...,    0,    0,    0],\n","        ...,\n","        [8087,   18, 2059, ...,    0,    0,    0],\n","        [8087,   16, 1436, ...,    0,    0,    0],\n","        [8087,   15,   57, ...,    0,    0,    0]])>)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"nBQuibYA4n0n"},"source":["## 位置エンコーディング\n","\n","このモデルには再帰や畳込みが含まれないので、モデルに文中の単語の相対的な位置の情報を与えるため、位置エンコーディングを追加します。\n","\n","位置エンコーディングベクトルは埋め込みベクトルに加算します。埋め込みはトークンをd次元空間で表現します。そこでは、同じような意味を持つトークンが近くに位置することになります。しかし、埋め込みは単語の文中の相対的位置をエンコードしません。したがって、位置エンコーディングを加えることで、単語は、d次元空間の中で、*意味と文中の位置の近さ*にもとづいて近くに位置づけられます。\n","\n","もう少し知りたければ [位置エンコーディング](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) のノートブックを参照してください。位置エンコーディングを計算する式は下記のとおりです。\n","\n","$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n","$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"]},{"cell_type":"code","metadata":{"id":"WhIOZjMNKujn","executionInfo":{"status":"ok","timestamp":1604737477166,"user_tz":-540,"elapsed":124675,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","  return pos * angle_rates"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Rz82wEs5biZ","executionInfo":{"status":"ok","timestamp":1604737477166,"user_tz":-540,"elapsed":124672,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  \n","  # 配列中の偶数インデックスにはsinを適用; 2i\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  \n","  # 配列中の奇数インデックスにはcosを適用; 2i+1\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    \n","  pos_encoding = angle_rads[np.newaxis, ...]\n","    \n","  return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kLCla68EloE","executionInfo":{"status":"ok","timestamp":1604737477558,"user_tz":-540,"elapsed":125061,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"90484030-5bbb-4941-d31a-a900d5996b97","colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["pos_encoding = positional_encoding(50, 512)\n","print (pos_encoding.shape)\n","\n","plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n","plt.xlabel('Depth')\n","plt.xlim((0, 512))\n","plt.ylabel('Position')\n","plt.colorbar()\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(1, 50, 512)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"a_b4ou4TYqUN"},"source":["## マスキング"]},{"cell_type":"markdown","metadata":{"id":"s42Uydjkv0hF"},"source":["シーケンスのバッチ中のパディングされた全てのトークンをマスクします。これにより、モデルがパディングを確実に入力として扱わないようにします。マスクは、パディング値`0`の存在を示します。つまり、`0`の場所で`1`を出力し、それ以外の場所では`0`を出力します。"]},{"cell_type":"code","metadata":{"id":"U2i8-e1s8ti9","executionInfo":{"status":"ok","timestamp":1604737477558,"user_tz":-540,"elapsed":125056,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def create_padding_mask(seq):\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","  \n","  # アテンション・ロジットにパディングを追加するため\n","  # さらに次元を追加する\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7BYeBCNvi7n","executionInfo":{"status":"ok","timestamp":1604737477559,"user_tz":-540,"elapsed":125054,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"fb5bc4bf-4225-452f-f527-d65d70caa992","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n","create_padding_mask(x)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n","array([[[[0., 0., 1., 1., 0.]]],\n","\n","\n","       [[[0., 0., 0., 1., 1.]]],\n","\n","\n","       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Z0hzukDBgVom"},"source":["シーケンス中の未来のトークンをマスクするため、 ルックアヘッド・マスクが使われています。言い換えると、このマスクはどのエントリーを使うべきではないかを示しています。\n","\n","これは、3番めの単語を予測するために、1つ目と2つ目の単語だけが使われるということを意味しています。同じように4つ目の単語を予測するには、1つ目、2つ目と3つ目の単語だけが使用され、次も同様となります。"]},{"cell_type":"code","metadata":{"id":"dVxS8OPI9uI0","executionInfo":{"status":"ok","timestamp":1604737477559,"user_tz":-540,"elapsed":125051,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def create_look_ahead_mask(size):\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","  return mask  # (seq_len, seq_len)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxKGuXxaBeeE","executionInfo":{"status":"ok","timestamp":1604737477560,"user_tz":-540,"elapsed":125049,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"a6f65611-b677-42db-cbdf-fc6f977a00ba","colab":{"base_uri":"https://localhost:8080/"}},"source":["x = tf.random.uniform((1, 3))\n","temp = create_look_ahead_mask(x.shape[1])\n","temp"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[0., 1., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"xluDl5cXYy4y"},"source":["## スケール済み内積アテンション"]},{"cell_type":"markdown","metadata":{"id":"vsxEE_-Wa1gF"},"source":["<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n","\n","Transformerで使われているアテンション関数は3つの入力；Q(query), K(key), V(value)を取ります。このアテンションの重みの計算に使われている式は下記の通りです。\n","\n","$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n","\n","内積アテンションは、深度の平方根をファクターとしてスケールされています。これは、深度が大きくなると、内積が非常に大きくなり、ソフトマックス関数の勾配を計算すると非常に小さな値しか返さなくなってしまうためです。\n","\n","例えば、`Q`と`K`が平均0分散1だと思ってください。これらの行列積は、平均0分散は`dk`となります。したがって、（他の数字ではなく）*`dk`の平方根*をスケーリングに使うことで、`Q` と `K` の行列積においても平均 0 分散 1 となり、緩やかな勾配を持つソフトマックスが得られることが期待できるのです。\n","\n","マスクには、（負の無限大に近い）-1e9が掛けられています。これは、マスクがQとKのスケール済み行列積と合計され、ソフトマックスの直前に適用されるからです。目的は、これらのセルをゼロにしてしまうことで、大きなマイナスの入力は、ゼロに近い出力となります。"]},{"cell_type":"code","metadata":{"id":"LazzUq3bJ5SH","executionInfo":{"status":"ok","timestamp":1604737477560,"user_tz":-540,"elapsed":125046,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def scaled_dot_product_attention(q, k, v, mask):\n","  \"\"\"アテンションの重みの計算\n","  q, k, vは最初の次元が一致していること\n","  k, vは最後から2番めの次元が一致していること\n","  マスクは型（パディングかルックアヘッドか）によって異なるshapeを持つが、\n","  加算の際にブロードキャスト可能であること\n","  引数：\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: (..., seq_len_q, seq_len_k) にブロードキャスト可能な\n","          shapeを持つ浮動小数点テンソル。既定値はNone\n","  \n","  戻り値：\n","    出力、アテンションの重み\n","  \"\"\"\n","\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","  \n","  # matmul_qkをスケール\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # マスクをスケール済みテンソルに加算\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax は最後の軸(seq_len_k)について\n","  # 合計が1となるように正規化\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","  return output, attention_weights"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FiqETnhCkoXh"},"source":["ソフトマックス正規化がKに対して行われるため、その値がQに割り当てる重要度を決めることになります。\n","\n","出力は、アテンションの重みとV(value)ベクトルの積を表しています。これにより、注目したい単語がそのまま残され、それ以外の単語は破棄されます。"]},{"cell_type":"code","metadata":{"id":"n90YjClyInFy","executionInfo":{"status":"ok","timestamp":1604737477561,"user_tz":-540,"elapsed":125044,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def print_out(q, k, v):\n","  temp_out, temp_attn = scaled_dot_product_attention(\n","      q, k, v, None)\n","  print ('Attention weights are:')\n","  print (temp_attn)\n","  print ('Output is:')\n","  print (temp_out)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAzUAf2DPlNt","executionInfo":{"status":"ok","timestamp":1604737477561,"user_tz":-540,"elapsed":125040,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"f0ab5ff5-728e-4f98-b67a-df8ad7d0d150","colab":{"base_uri":"https://localhost:8080/"}},"source":["np.set_printoptions(suppress=True)\n","\n","temp_k = tf.constant([[10,0,0],\n","                      [0,10,0],\n","                      [0,0,10],\n","                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n","\n","temp_v = tf.constant([[   1,0],\n","                      [  10,0],\n","                      [ 100,5],\n","                      [1000,6]], dtype=tf.float32)  # (4, 2)\n","\n","# この`query`は2番目の`key`に割り付けられているので\n","# 2番めの`value`が返される\n","temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n","print_out(temp_q, temp_k, temp_v)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zg6k-fGhgXra","executionInfo":{"status":"ok","timestamp":1604737477562,"user_tz":-540,"elapsed":125038,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"777b7f84-5a4f-4e03-a597-c9b3aa461c0f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# このクエリは（3番目と 4番目の）繰り返しキーに割り付けられるので\n","# 関連した全ての値が平均される\n","temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n","print_out(temp_q, temp_k, temp_v)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UAq3YOzUgXhb","executionInfo":{"status":"ok","timestamp":1604737477562,"user_tz":-540,"elapsed":125036,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"10e343c0-95cd-425a-ad41-3014041f8e90","colab":{"base_uri":"https://localhost:8080/"}},"source":["# このクエリは最初と2番めのキーに等しく割り付けられるので\n","# それらの値が平均される\n","temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n","print_out(temp_q, temp_k, temp_v)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aOz-4_XIhaTP"},"source":["すべてのクエリをまとめます。"]},{"cell_type":"code","metadata":{"id":"6dlU8Tm-hYrF","executionInfo":{"status":"ok","timestamp":1604737477563,"user_tz":-540,"elapsed":125032,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"33f1cdc8-5767-45ef-9f70-3b38f2d04ead","colab":{"base_uri":"https://localhost:8080/"}},"source":["temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n","print_out(temp_q, temp_k, temp_v)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor(\n","[[0.  0.  0.5 0.5]\n"," [0.  1.  0.  0. ]\n"," [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n","Output is:\n","tf.Tensor(\n","[[550.    5.5]\n"," [ 10.    0. ]\n"," [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kmzGPEy64qmA"},"source":["## マルチヘッド・アテンション"]},{"cell_type":"markdown","metadata":{"id":"fz5BMC8Kaoqo"},"source":["<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n","\n","\n","マルチヘッド・アテンションは4つのパートから成っています。\n","* 線形レイヤーとマルチヘッドへの分割\n","* スケール済み内積アテンション\n","* マルチヘッドの結合\n","* 最終線形レイヤー\n"]},{"cell_type":"markdown","metadata":{"id":"JPmbr6F1C-v_"},"source":["各マルチヘッド・アテンション・ブロックは3つの入力：Q(query), K(key), V(value)を取ります。\n","これらは、線形（Dense）レイヤーを通され、マルチヘッドに分割されます。\n","\n","上記で定義した`scaled_dot_product_attention`は（効率のためにブロードキャストで）各ヘッドに適用されます。アテンション・ステップにおいては、適切なマスクを使用しなければなりません。その後、各ヘッドのアテンション出力は（`tf.transpose`と`tf.reshape`を使って）結合され、最後の`Dense`レイヤーに通されます。\n","\n","単一のアテンション・ヘッドのかわりに、Q、K、およびVは複数のヘッドに分割されます。なぜなら、それによって、モデルが異なる表現空間の異なる位置の情報について、連携してアテンションを計算できるからです。また、分割後の各ヘッドの次元を小さくすることで、全体の計算コストを、すべての次元を持つ単一のアテンション・ヘッドを用いた場合と同一にできます。"]},{"cell_type":"code","metadata":{"id":"BSV3PPKsYecw","executionInfo":{"status":"ok","timestamp":1604737477790,"user_tz":-540,"elapsed":125256,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x, batch_size):\n","    \"\"\"最後の次元を(num_heads, depth)に分割。\n","    結果をshapeが(batch_size, num_heads, seq_len, depth)となるようにリシェイプする。\n","    \"\"\"\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","    \n","    q = self.wq(q)  # (batch_size, seq_len, d_model)\n","    k = self.wk(k)  # (batch_size, seq_len, d_model)\n","    v = self.wv(v)  # (batch_size, seq_len, d_model)\n","    \n","    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","    \n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\n","        q, k, v, mask)\n","    \n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","    return output, attention_weights"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0D8FJue5lDyZ"},"source":["試しに、`MultiHeadAttention`レイヤーを作ってみましょう。シーケンス `y` の各位置において、`MultiHeadAttention` はシーケンスのすべての位置に対して8つのヘッドを用いてアテンションを計算し、各位置それぞれで同じ長さの新しいベクトルを返します。"]},{"cell_type":"code","metadata":{"id":"Hu94p-_-2_BX","executionInfo":{"status":"ok","timestamp":1604737477791,"user_tz":-540,"elapsed":125254,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"485a7710-0e17-4f68-e628-895c0d7f1f57","colab":{"base_uri":"https://localhost:8080/"}},"source":["temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n","y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n","out, attn = temp_mha(y, k=y, q=y, mask=None)\n","out.shape, attn.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"RdDqGayx67vv"},"source":["## ポイントワイズのフィードフォワード・ネットワーク"]},{"cell_type":"markdown","metadata":{"id":"gBqzJXGfHK3X"},"source":["ポイントワイズのフィードフォワード・ネットワークは、2つの全結合層とそれをつなぐReLU活性化層からなります。"]},{"cell_type":"code","metadata":{"id":"ET7xLt0yCT6Z","executionInfo":{"status":"ok","timestamp":1604737477791,"user_tz":-540,"elapsed":125251,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"mytb1lPyOHLB","executionInfo":{"status":"ok","timestamp":1604737478002,"user_tz":-540,"elapsed":125459,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"92186307-1366-45c1-d386-8ef2696a1039","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_ffn = point_wise_feed_forward_network(512, 2048)\n","sample_ffn(tf.random.uniform((64, 50, 512))).shape"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 50, 512])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"7e7hKcxn6-zd"},"source":["## エンコーダーとデコーダー"]},{"cell_type":"markdown","metadata":{"id":"yScbC0MUH8dS"},"source":["<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"]},{"cell_type":"markdown","metadata":{"id":"MfYJG-Kvgwy2"},"source":["Transformerモデルは、標準の[アテンション付きシーケンス・トゥー・シーケンスモデル](nmt_with_attention.ipynb)と同じ一般的なパターンを踏襲します。\n","\n","* 入力の文は、`N`層のエンコーダー・レイヤーを通り、シーケンス中の単語／トークンごとに出力を生成する。\n","* デコーダーは、エンコーダーの出力と自分自身の入力（セルフアテンション）に注目し、次の単語を予測する。"]},{"cell_type":"markdown","metadata":{"id":"QFv-FNYUmvpn"},"source":["### エンコーダー・レイヤー\n","\n","それぞれのエンコーダー・レイヤーは次のようなサブレイヤーから成っています。\n","\n","1.  マルチヘッド・アテンション（パディング・マスク付き）\n","2.  ポイントワイズ・フィードフォワード・ネットワーク\n","\n","サブレイヤーにはそれぞれ残差接続があり、その後にレイヤー正規化が続きます。残差接続は、深いネットワークでの勾配消失問題を回避するのに役立ちます。\n","\n","それぞれのサブレイヤーの出力は`LayerNorm(x + Sublayer(x))`です。正規化は、（最後の）`d_model`軸に対して行われます。TransformerにはN層のエンコーダーがあります。"]},{"cell_type":"code","metadata":{"id":"ncyS-Ms3i2x_","executionInfo":{"status":"ok","timestamp":1604737478003,"user_tz":-540,"elapsed":125457,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training, mask):\n","\n","    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    return out2"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"AzZRXdO0mI48","executionInfo":{"status":"ok","timestamp":1604737478545,"user_tz":-540,"elapsed":125996,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"4c0427a7-1b37-415b-e17a-e9f6e1380619","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_encoder_layer = EncoderLayer(512, 8, 2048)\n","\n","sample_encoder_layer_output = sample_encoder_layer(\n","    tf.random.uniform((64, 43, 512)), False, None)\n","\n","sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 43, 512])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"6LO_48Owmx_o"},"source":["### デコーダー・レイヤー\n","\n","各デコーダー・レイヤーは次のようなサブレイヤーからなります。\n","\n","1. マスク付きマルチヘッド・アテンション（ ルックアヘッド・マスクおよびパディング・マスク付き）\n","2. （パディング・マスク付き）マルチヘッド・アテンション。V(value) と K(key) は*エンコーダーの出力*を入力として受け取る。Q(query)は*マスク付きマルチヘッド・アテンション・サブレイヤー*の出力を受け取る。\n","3. ポイントワイズ・フィードフォワード・ネットワーク\n","\n","各サブレイヤーは残差接続を持ち、その後にレイヤー正規化が続きます。各サブレイヤーの出力は`LayerNorm(x + Sublayer(x))`です。正規化は、（最後の）`d_model`軸に沿って行われます。\n","\n","Transformerには、N層のデコーダー・レイヤーが存在します。\n","\n","Qがデコーダーの最初のアテンション・ブロックの出力を受け取り、Kがエンコーダーの出力を受け取るとき、アテンションの重みは、デコーダーの入力の、エンコーダーの出力に対する重要度を表します。言い換えると、デコーダーは、エンコーダーの出力と自分自身の出力のセルフ・アテンションを見て、次の単語を予想します。上記の、スケール済み内積アテンションのセクションのデモを参照してください。"]},{"cell_type":"code","metadata":{"id":"9SoX0-vd1hue","executionInfo":{"status":"ok","timestamp":1604737478546,"user_tz":-540,"elapsed":125994,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n"," \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","    attn1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(attn1 + x)\n","    \n","    attn2, attn_weights_block2 = self.mha2(\n","        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","    attn2 = self.dropout2(attn2, training=training)\n","    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","    \n","    return out3, attn_weights_block1, attn_weights_block2"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ne2Bqx8k71l0","executionInfo":{"status":"ok","timestamp":1604737479260,"user_tz":-540,"elapsed":126705,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"3ca68e19-b6f3-4fe0-96ce-bfd7bbd64189","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_decoder_layer = DecoderLayer(512, 8, 2048)\n","\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(\n","    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n","    False, None, None)\n","\n","sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 50, 512])"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"SE1H51Ajm0q1"},"source":["### エンコーダー\n","\n","`Encoder`は次のものからできています。\n","\n","1.  入力の埋め込み\n","2.  位置エンコーディング\n","3.  N 層のエンコーダー・レイヤー\n","\n","入力は埋め込み層を通り、位置エンコーディングと合算されます。この加算の出力がエンコーダー・レイヤーの入力です。エンコーダーの出力はデコーダーの入力になります。"]},{"cell_type":"code","metadata":{"id":"jpEox7gJ8FCI","executionInfo":{"status":"ok","timestamp":1604737479260,"user_tz":-540,"elapsed":126702,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, \n","                                            self.d_model)\n","    \n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","  def call(self, x, training, mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    \n","    # 埋め込みと位置エンコーディングを合算する\n","    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training, mask)\n","    \n","    return x  # (batch_size, input_seq_len, d_model)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QG9nueFQKXx","executionInfo":{"status":"ok","timestamp":1604737480745,"user_tz":-540,"elapsed":128184,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"95bfe125-cbc4-4ddc-8689-8dd495d78d1d","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n","                         dff=2048, input_vocab_size=8500,\n","                         maximum_position_encoding=10000)\n","temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n","\n","sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n","\n","print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["(64, 62, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p-uO6ls8m2O5"},"source":["### デコーダー"]},{"cell_type":"markdown","metadata":{"id":"ZtT7PKzrXkNr"},"source":["`Decoder` は次のもとからできています。\n"," \n","1.   出力埋め込み\n","2.   位置エンコーディング\n","3.   N 層のデコーダー・レイヤー\n","\n","ターゲットは埋め込みを通り、位置エンコーディングと加算されます。この加算の出力がデコーダーの入力になります。デコーダーの出力は、最後の線形レイヤーの入力となります。"]},{"cell_type":"code","metadata":{"id":"d5_d5-PLQXwY","executionInfo":{"status":"ok","timestamp":1604737480746,"user_tz":-540,"elapsed":128181,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","    \n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    \n","    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","    \n","    x = self.dropout(x, training=training)\n","\n","    for i in range(self.num_layers):\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                             look_ahead_mask, padding_mask)\n","      \n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","    # x.shape == (batch_size, target_seq_len, d_model)\n","    return x, attention_weights"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1jXoAMRZyvu","executionInfo":{"status":"ok","timestamp":1604737481790,"user_tz":-540,"elapsed":129222,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"156d3119-a56b-4f74-8ee2-be7fe7f3f233","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n","                         dff=2048, target_vocab_size=8000,\n","                         maximum_position_encoding=5000)\n","temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n","\n","output, attn = sample_decoder(temp_input, \n","                              enc_output=sample_encoder_output, \n","                              training=False,\n","                              look_ahead_mask=None, \n","                              padding_mask=None)\n","\n","output.shape, attn['decoder_layer2_block2'].shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"y54xnJnuYgJ7"},"source":["## Transformerの作成"]},{"cell_type":"markdown","metadata":{"id":"uERO1y54cOKq"},"source":[" Transformerは、エンコーダー、デコーダーと、最後の線形レイヤーからなります。デコーダーの出力は、線形レイヤーの入力であり、その出力が返されます。"]},{"cell_type":"code","metadata":{"id":"PED3bIpOYkBu","executionInfo":{"status":"ok","timestamp":1604737481791,"user_tz":-540,"elapsed":129220,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n","               target_vocab_size, pe_input, pe_target, rate=0.1):\n","    super(Transformer, self).__init__()\n","\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n","                           input_vocab_size, pe_input, rate)\n","\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n","                           target_vocab_size, pe_target, rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","  def call(self, inp, tar, training, enc_padding_mask, \n","           look_ahead_mask, dec_padding_mask):\n","\n","    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","    \n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","    dec_output, attention_weights = self.decoder(\n","        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","    \n","    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","    \n","    return final_output, attention_weights"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJ4fbQcIkHW1","executionInfo":{"status":"ok","timestamp":1604737484634,"user_tz":-540,"elapsed":132059,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"f66761a6-d40c-4da4-8041-2bf98bf304b1","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample_transformer = Transformer(\n","    num_layers=2, d_model=512, num_heads=8, dff=2048, \n","    input_vocab_size=8500, target_vocab_size=8000, \n","    pe_input=10000, pe_target=6000)\n","\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n","\n","fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n","                               enc_padding_mask=None, \n","                               look_ahead_mask=None,\n","                               dec_padding_mask=None)\n","\n","fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 36, 8000])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"wsINyf1VEQLC"},"source":["## ハイパーパラメーターの設定"]},{"cell_type":"markdown","metadata":{"id":"zVjWCxFNcgbt"},"source":["このサンプルを小さく、比較的高速にするため、 *num_layers, d_model, and dff*の値は小さくされています。\n","\n","Transformerのベースモデルで使われている値は*num_layers=6*, *d_model = 512*, *dff = 2048*です。 Transformerの他のバージョンについては、[論文](https://arxiv.org/abs/1706.03762)を参照してください。\n","\n","Note: 下記の値を変更することで、さまざまなタスクでSoTA（訳注：State of The Art、その時点での最高性能）を達成したモデルが得られます。"]},{"cell_type":"code","metadata":{"id":"lnJn5SLA2ahP","executionInfo":{"status":"ok","timestamp":1604737484634,"user_tz":-540,"elapsed":132056,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","\n","input_vocab_size = tokenizer_pt.vocab_size + 2\n","target_vocab_size = tokenizer_en.vocab_size + 2\n","dropout_rate = 0.1"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xYEGhEOtzn5W"},"source":["## オプティマイザー"]},{"cell_type":"markdown","metadata":{"id":"GOmWW--yP3zx"},"source":["[論文](https://arxiv.org/abs/1706.03762)の中の式に従って、カスタムの学習率スケジューラーを持った、Adamオプティマイザーを使用します。\n","\n","$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"]},{"cell_type":"code","metadata":{"id":"iYQdOO1axwEI","executionInfo":{"status":"ok","timestamp":1604737484635,"user_tz":-540,"elapsed":132054,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"7r4scdulztRx","executionInfo":{"status":"ok","timestamp":1604737484635,"user_tz":-540,"elapsed":132050,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"f33ZCgvHpPdG","executionInfo":{"status":"ok","timestamp":1604737484636,"user_tz":-540,"elapsed":132048,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"9688e8b9-08bb-4bf0-99ad-7e68385ca861","colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{"tags":[]},"execution_count":49},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YgkDE7hzo8r5"},"source":["## 損失とメトリクス"]},{"cell_type":"markdown","metadata":{"id":"oxGJtoDuYIHL"},"source":["ターゲットシーケンスはパディングされているため、損失を計算する際にパディング・マスクを適用することが重要です。"]},{"cell_type":"code","metadata":{"id":"MlhsJMm0TW_B","executionInfo":{"status":"ok","timestamp":1604737484637,"user_tz":-540,"elapsed":132046,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"67oqVHiT0Eiu","executionInfo":{"status":"ok","timestamp":1604737484637,"user_tz":-540,"elapsed":132041,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_mean(loss_)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"phlyxMnm-Tpx","executionInfo":{"status":"ok","timestamp":1604737484638,"user_tz":-540,"elapsed":132037,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aeHumfr7zmMa"},"source":["## 訓練とチェックポイント生成"]},{"cell_type":"code","metadata":{"id":"UiysUa--4tOU","executionInfo":{"status":"ok","timestamp":1604737484855,"user_tz":-540,"elapsed":132251,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=input_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOJUSB1T8GjM","executionInfo":{"status":"ok","timestamp":1604737484855,"user_tz":-540,"elapsed":132247,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def create_masks(inp, tar):\n","  # Encoderパディング・マスク\n","  enc_padding_mask = create_padding_mask(inp)\n","  \n","  # デコーダーの 2つ目のアテンション・ブロックで使用\n","  # このパディング・マスクはエンコーダーの出力をマスクするのに使用\n","  dec_padding_mask = create_padding_mask(inp)\n","  \n","  # デコーダーの 1つ目のアテンション・ブロックで使用\n","  # デコーダーが受け取った入力のパディングと将来のトークンをマスクするのに使用\n","  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","  dec_target_padding_mask = create_padding_mask(tar)\n","  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","  return enc_padding_mask, combined_mask, dec_padding_mask"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fzuf06YZp66w"},"source":["チェックポイントのパスとチェックポイント・マネージャーを作成します。これは、`n`エポックごとにチェックポイントを保存するのに使用されます。"]},{"cell_type":"code","metadata":{"id":"hNhuYfllndLZ","executionInfo":{"status":"ok","timestamp":1604737484855,"user_tz":-540,"elapsed":132241,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["checkpoint_path = \"./checkpoints/train\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# チェックポイントが存在したなら、最後のチェックポイントを復元\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Di_Yaa1gf9r"},"source":["ターゲットは、tar_inpとtar_realに分けられます。tar_inpはデコーダーの入力として渡されます。`tar_real`は同じ入力を1つシフトしたものです。`tar_input`の位置それぞれで、`tar_real`は予測されるべき次のトークンを含んでいます。\n","\n","たとえば、`sentence` = \"SOS A lion in the jungle is sleeping EOS\" だとすると、次のようになります。\n","\n","`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n","\n","`tar_real` = \"A lion in the jungle is sleeping EOS\"\n","\n","Transformerは、自己回帰モデルです。1回に1箇所の予測を行い、その出力を次に何をすべきかの判断に使用します。\n","\n","訓練時にこのサンプルは[テキスト生成チュートリアル](./text_generation.ipynb)のように、ティーチャーフォーシングを使用します。ティーチャーフォーシングとは、その時点においてモデルが何を予測したかに関わらず、真の出力を次のステップに渡すというものです。\n","\n","Transformerが単語を予測するたびに、*セルフアテンション*のおかげで次の単語を予測するために入力シーケンスの過去の単語を参照することができます。\n","\n","モデルが期待される出力を盗み見ることがないように、モデルはルックアヘッド・マスクを使用します。"]},{"cell_type":"code","metadata":{"id":"LKpoA6q1sJFj","executionInfo":{"status":"ok","timestamp":1604737484856,"user_tz":-540,"elapsed":132237,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["EPOCHS = 20"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJwmp9OE29oj","executionInfo":{"status":"ok","timestamp":1604737484856,"user_tz":-540,"elapsed":132231,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# @tf.functionは高速に実行するためにtrain_stepをTFグラフにトレースコンパイルします。\n","# この関数は、引数となるテンソルのshapeに特化したものです。\n","# シーケンスの長さや（最後のバッチが小さくなるなど）バッチサイズが可変となることによって\n","# 再トレーシングが起きないようにするため、input_signatureを使って、より一般的なshapeを\n","# 指定します。\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  \n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)"],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qM2PDWGDJ_8V"},"source":["ポルトガル語を入力言語とし、英語をターゲット言語とします。"]},{"cell_type":"code","metadata":{"id":"bbvmaKNiznHZ","outputId":"033d3a97-582b-4e7c-865d-b38a5d53bc21","colab":{"base_uri":"https://localhost:8080/"}},"source":["for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  # inp -> portuguese, tar -> english\n","  for (batch, (inp, tar)) in enumerate(train_dataset):\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 3.6535 Accuracy 0.0000\n","Epoch 1 Batch 50 Loss 4.1667 Accuracy 0.0021\n","Epoch 1 Batch 100 Loss 4.1453 Accuracy 0.0129\n","Epoch 1 Batch 150 Loss 4.1038 Accuracy 0.0176\n","Epoch 1 Batch 200 Loss 4.0451 Accuracy 0.0201\n","Epoch 1 Batch 250 Loss 3.9765 Accuracy 0.0220\n","Epoch 1 Batch 300 Loss 3.8987 Accuracy 0.0245\n","Epoch 1 Batch 350 Loss 3.8140 Accuracy 0.0290\n","Epoch 1 Batch 400 Loss 3.7281 Accuracy 0.0330\n","Epoch 1 Batch 450 Loss 3.6494 Accuracy 0.0361\n","Epoch 1 Batch 500 Loss 3.5847 Accuracy 0.0390\n","Epoch 1 Batch 550 Loss 3.5263 Accuracy 0.0423\n","Epoch 1 Batch 600 Loss 3.4659 Accuracy 0.0459\n","Epoch 1 Batch 650 Loss 3.4104 Accuracy 0.0493\n","Epoch 1 Batch 700 Loss 3.3603 Accuracy 0.0526\n","Epoch 1 Loss 3.3591 Accuracy 0.0527\n","Time taken for 1 epoch: 992.2440252304077 secs\n","\n","Epoch 2 Batch 0 Loss 2.8276 Accuracy 0.1031\n","Epoch 2 Batch 50 Loss 2.5617 Accuracy 0.1016\n","Epoch 2 Batch 100 Loss 2.5329 Accuracy 0.1052\n","Epoch 2 Batch 150 Loss 2.5283 Accuracy 0.1076\n","Epoch 2 Batch 200 Loss 2.5062 Accuracy 0.1091\n","Epoch 2 Batch 250 Loss 2.4891 Accuracy 0.1113\n","Epoch 2 Batch 300 Loss 2.4725 Accuracy 0.1129\n","Epoch 2 Batch 350 Loss 2.4589 Accuracy 0.1147\n","Epoch 2 Batch 400 Loss 2.4422 Accuracy 0.1163\n","Epoch 2 Batch 450 Loss 2.4310 Accuracy 0.1181\n","Epoch 2 Batch 500 Loss 2.4124 Accuracy 0.1194\n","Epoch 2 Batch 550 Loss 2.4019 Accuracy 0.1208\n","Epoch 2 Batch 600 Loss 2.3926 Accuracy 0.1223\n","Epoch 2 Batch 650 Loss 2.3838 Accuracy 0.1236\n","Epoch 2 Batch 700 Loss 2.3715 Accuracy 0.1248\n","Epoch 2 Loss 2.3708 Accuracy 0.1248\n","Time taken for 1 epoch: 902.2621688842773 secs\n","\n","Epoch 3 Batch 0 Loss 2.0048 Accuracy 0.1345\n","Epoch 3 Batch 50 Loss 2.1822 Accuracy 0.1433\n","Epoch 3 Batch 100 Loss 2.1704 Accuracy 0.1433\n","Epoch 3 Batch 150 Loss 2.1630 Accuracy 0.1441\n","Epoch 3 Batch 200 Loss 2.1537 Accuracy 0.1443\n","Epoch 3 Batch 250 Loss 2.1474 Accuracy 0.1450\n","Epoch 3 Batch 300 Loss 2.1360 Accuracy 0.1454\n","Epoch 3 Batch 350 Loss 2.1341 Accuracy 0.1462\n","Epoch 3 Batch 400 Loss 2.1332 Accuracy 0.1468\n","Epoch 3 Batch 450 Loss 2.1262 Accuracy 0.1475\n","Epoch 3 Batch 500 Loss 2.1197 Accuracy 0.1481\n","Epoch 3 Batch 550 Loss 2.1180 Accuracy 0.1490\n","Epoch 3 Batch 600 Loss 2.1140 Accuracy 0.1498\n","Epoch 3 Batch 650 Loss 2.1078 Accuracy 0.1507\n","Epoch 3 Batch 700 Loss 2.0999 Accuracy 0.1515\n","Epoch 3 Loss 2.0998 Accuracy 0.1515\n","Time taken for 1 epoch: 917.3493406772614 secs\n","\n","Epoch 4 Batch 0 Loss 1.8592 Accuracy 0.1562\n","Epoch 4 Batch 50 Loss 1.9050 Accuracy 0.1653\n","Epoch 4 Batch 100 Loss 1.9050 Accuracy 0.1654\n","Epoch 4 Batch 150 Loss 1.9151 Accuracy 0.1668\n","Epoch 4 Batch 200 Loss 1.9195 Accuracy 0.1681\n","Epoch 4 Batch 250 Loss 1.9173 Accuracy 0.1692\n","Epoch 4 Batch 300 Loss 1.9163 Accuracy 0.1705\n","Epoch 4 Batch 350 Loss 1.9108 Accuracy 0.1716\n","Epoch 4 Batch 400 Loss 1.9075 Accuracy 0.1730\n","Epoch 4 Batch 450 Loss 1.9008 Accuracy 0.1739\n","Epoch 4 Batch 500 Loss 1.8906 Accuracy 0.1748\n","Epoch 4 Batch 550 Loss 1.8832 Accuracy 0.1762\n","Epoch 4 Batch 600 Loss 1.8755 Accuracy 0.1772\n","Epoch 4 Batch 650 Loss 1.8696 Accuracy 0.1783\n","Epoch 4 Batch 700 Loss 1.8612 Accuracy 0.1791\n","Epoch 4 Loss 1.8614 Accuracy 0.1792\n","Time taken for 1 epoch: 972.8904662132263 secs\n","\n","Epoch 5 Batch 0 Loss 1.8774 Accuracy 0.1961\n","Epoch 5 Batch 50 Loss 1.7299 Accuracy 0.1968\n","Epoch 5 Batch 100 Loss 1.7084 Accuracy 0.1972\n","Epoch 5 Batch 150 Loss 1.7064 Accuracy 0.1991\n","Epoch 5 Batch 200 Loss 1.7010 Accuracy 0.2000\n","Epoch 5 Batch 250 Loss 1.6896 Accuracy 0.2010\n","Epoch 5 Batch 300 Loss 1.6824 Accuracy 0.2013\n","Epoch 5 Batch 350 Loss 1.6780 Accuracy 0.2019\n","Epoch 5 Batch 400 Loss 1.6727 Accuracy 0.2024\n","Epoch 5 Batch 450 Loss 1.6692 Accuracy 0.2033\n","Epoch 5 Batch 500 Loss 1.6648 Accuracy 0.2039\n","Epoch 5 Batch 550 Loss 1.6602 Accuracy 0.2045\n","Epoch 5 Batch 600 Loss 1.6569 Accuracy 0.2051\n","Epoch 5 Batch 650 Loss 1.6520 Accuracy 0.2055\n","Epoch 5 Batch 700 Loss 1.6485 Accuracy 0.2061\n","Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n","Epoch 5 Loss 1.6487 Accuracy 0.2061\n","Time taken for 1 epoch: 899.4693281650543 secs\n","\n","Epoch 6 Batch 0 Loss 1.6278 Accuracy 0.2399\n","Epoch 6 Batch 50 Loss 1.4955 Accuracy 0.2188\n","Epoch 6 Batch 100 Loss 1.4948 Accuracy 0.2207\n","Epoch 6 Batch 150 Loss 1.4853 Accuracy 0.2199\n","Epoch 6 Batch 200 Loss 1.4861 Accuracy 0.2200\n","Epoch 6 Batch 250 Loss 1.4859 Accuracy 0.2212\n","Epoch 6 Batch 300 Loss 1.4848 Accuracy 0.2217\n","Epoch 6 Batch 350 Loss 1.4849 Accuracy 0.2227\n","Epoch 6 Batch 400 Loss 1.4805 Accuracy 0.2230\n","Epoch 6 Batch 450 Loss 1.4786 Accuracy 0.2233\n","Epoch 6 Batch 500 Loss 1.4766 Accuracy 0.2239\n","Epoch 6 Batch 550 Loss 1.4693 Accuracy 0.2242\n","Epoch 6 Batch 600 Loss 1.4670 Accuracy 0.2245\n","Epoch 6 Batch 650 Loss 1.4671 Accuracy 0.2250\n","Epoch 6 Batch 700 Loss 1.4645 Accuracy 0.2256\n","Epoch 6 Loss 1.4644 Accuracy 0.2256\n","Time taken for 1 epoch: 944.0264081954956 secs\n","\n","Epoch 7 Batch 0 Loss 1.1340 Accuracy 0.2121\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QfcsSWswSdGV"},"source":["## 評価"]},{"cell_type":"markdown","metadata":{"id":"y6APsFrgImLW"},"source":["評価は次のようなステップで行われます。\n","\n","* ポルトガル語のトークナイザー(`tokenizer_pt`)を使用して入力文をエンコードします。さらに、モデルの訓練に使用されたものと同様に、開始および終了トークンを追加します。これが、入力のエンコードです。\n","* デコーダーの入力は、`start token == tokenizer_en.vocab_size`です。\n","* パディング・マスクとルックアヘッド・マスクを計算します。\n","* `decoder`は、`encoder output`と自分自身の出力（セルフアテンション）を見て、予測値を出力します。\n","* 最後の単語を選択し、そのargmaxを計算します。\n","* デコーダーの入力に予測された単語を結合し、デコーダーに渡します。\n","* このアプローチでは、デコーダーは自分自身が予測した過去の単語にもとづいて次の単語を予測します。\n","\n","Note: ここで使われているモデルは、より早く実行できるようにした能力の低いものであるため、予測はあまり正確ではありません。論文の結果を再現するには、データセット全体を使用し、上記のハイパーパラメーターを変更して、ベースのTransformerモデルまたはTransformer XLを使用します。"]},{"cell_type":"code","metadata":{"id":"5buvMlnvyrFm"},"source":["def evaluate(inp_sentence):\n","  start_token = [tokenizer_pt.vocab_size]\n","  end_token = [tokenizer_pt.vocab_size + 1]\n","  \n","  # inp文はポルトガル語、開始および終了トークンを追加\n","  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n","  encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","  # ターゲットは英語であるため、Transformerに与える最初の単語は英語の\n","  # 開始トークンとなる\n","  decoder_input = [tokenizer_en.vocab_size]\n","  output = tf.expand_dims(decoder_input, 0)\n","    \n","  for i in range(MAX_LENGTH):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","  \n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions, attention_weights = transformer(encoder_input, \n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    \n","    # seq_len次元から最後の単語を選択\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","    \n","    # predicted_idが終了トークンと等しいなら結果を返す\n","    if predicted_id == tokenizer_en.vocab_size+1:\n","      return tf.squeeze(output, axis=0), attention_weights\n","    \n","    # 出力にpredicted_idを結合し、デコーダーへの入力とする\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0), attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN-BV43FMBej"},"source":["def plot_attention_weights(attention, sentence, result, layer):\n","  fig = plt.figure(figsize=(16, 8))\n","  \n","  sentence = tokenizer_pt.encode(sentence)\n","  \n","  attention = tf.squeeze(attention[layer], axis=0)\n","  \n","  for head in range(attention.shape[0]):\n","    ax = fig.add_subplot(2, 4, head+1)\n","    \n","    # アテンションの重みをプロット\n","    ax.matshow(attention[head][:-1, :], cmap='viridis')\n","\n","    fontdict = {'fontsize': 10}\n","    \n","    ax.set_xticks(range(len(sentence)+2))\n","    ax.set_yticks(range(len(result)))\n","    \n","    ax.set_ylim(len(result)-1.5, -0.5)\n","        \n","    ax.set_xticklabels(\n","        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n","        fontdict=fontdict, rotation=90)\n","    \n","    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n","                        if i < tokenizer_en.vocab_size], \n","                       fontdict=fontdict)\n","    \n","    ax.set_xlabel('Head {}'.format(head+1))\n","  \n","  plt.tight_layout()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lU2_yG_vBGza"},"source":["def translate(sentence, plot=''):\n","  result, attention_weights = evaluate(sentence)\n","  \n","  predicted_sentence = tokenizer_en.decode([i for i in result \n","                                            if i < tokenizer_en.vocab_size])  \n","\n","  print('Input: {}'.format(sentence))\n","  print('Predicted translation: {}'.format(predicted_sentence))\n","  \n","  if plot:\n","    plot_attention_weights(attention_weights, sentence, result, plot)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsxrAlvFG8SZ"},"source":["translate(\"este é um problema que temos que resolver.\")\n","print (\"Real translation: this is a problem we have to solve .\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EH5y_aqI4t1"},"source":["translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n","print (\"Real translation: and my neighboring homes heard about this idea .\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-hVCTSUMlkb"},"source":["translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n","print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1MxkSZvz0jX"},"source":["パラメータを`plot`するために、異なるレイヤーやデコーダーのアテンション・ブロックを渡すことができます。"]},{"cell_type":"code","metadata":{"id":"t-kFyiOLH0xg"},"source":["translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n","print (\"Real translation: this is the first book i've ever done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqQ1fIsLwkGE"},"source":["## まとめ\n","\n","このチュートリアルでは、位置エンコーディング、マルチヘッド・アテンション、マスキングの重要性と、 Transformerの作成方法を学習しました。\n","\n","Transformerを訓練するために、異なるデータセットを使ってみてください。また、上記のハイパーパラメーターを変更してベースTransformerやTransformer XLを構築することもできます。ここで定義したレイヤーを使って[BERT](https://arxiv.org/abs/1810.04805)を構築して、SoTAのモデルを作ることもできます。さらには、より良い予測を得るために、ビームサーチを組み込むこともできます。"]}]}